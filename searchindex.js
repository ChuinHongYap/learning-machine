Search.setIndex({docnames:["basic/approx/approx","basic/basic","basic/gradients/gradients","basic/gradients/loss-fn-derivative","basic/gradients/torch-cal-grads","generative/ae/ae","generative/ae/vae/vae","generative/gan/gan","generative/generative","intro","layers/cnn/cnn","layers/dropout/dropout","layers/emb/emb","layers/layers","layers/linear/linear","layers/linear/linear-grad","layers/norm/norm","layers/padding/padding","layers/pooling/pooling","layers/rnn/rnn","layers/transformer/attn/attn","layers/transformer/transformer","layers/transformer/transformer-vs-rnn","tasks/classification/classification","tasks/classification/gmm","tasks/regression/em-algo","tasks/regression/regression","tasks/tasks"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,sphinx:56},filenames:["basic/approx/approx.md","basic/basic.md","basic/gradients/gradients.md","basic/gradients/loss-fn-derivative.md","basic/gradients/torch-cal-grads.md","generative/ae/ae.md","generative/ae/vae/vae.md","generative/gan/gan.md","generative/generative.md","intro.md","layers/cnn/cnn.md","layers/dropout/dropout.md","layers/emb/emb.md","layers/layers.md","layers/linear/linear.md","layers/linear/linear-grad.md","layers/norm/norm.md","layers/padding/padding.md","layers/pooling/pooling.md","layers/rnn/rnn.md","layers/transformer/attn/attn.md","layers/transformer/transformer.md","layers/transformer/transformer-vs-rnn.md","tasks/classification/classification.md","tasks/classification/gmm.md","tasks/regression/em-algo.md","tasks/regression/regression.md","tasks/tasks.md"],objects:{},objnames:{},objtypes:{},terms:{"case":1,"switch":4,And:1,For:14,The:1,There:[1,14],Use:14,Yes:3,about:1,academ:9,add:9,algorithm:3,all:9,also:[10,14,19],anoth:14,answer:9,artifici:1,asid:1,auto:6,basic:9,behind:0,being:1,bia:14,branch:1,call:[1,14],calm:1,can:[1,14],certainli:1,chang:[6,14],cnn:10,complet:9,compon:14,comput:1,concret:9,consider:6,cover:[1,9],data:10,deal:1,decept:1,deep:[0,1],dens:14,descent:3,descript:9,differ:[6,14],dimens:14,doe:[1,3],don:9,either:9,elon:1,encod:6,equal:1,evalu:3,everywher:9,exampl:14,explan:4,fear:1,feel:0,filter:1,focu:4,focus:[0,1],free:0,from:[1,6,14],geometr:10,good:4,googl:1,gradient:3,grasp:0,hand:14,happen:14,has:[3,4],have:[1,10],help:1,howev:[1,3,9],incred:1,inform:1,input:[6,14],instead:9,intellig:1,intention:11,interchang:1,internet:1,intuit:[0,9],job:1,joke:1,just:1,kera:14,land:1,learn:[0,9],leverag:1,like:[1,9,14],liter:9,lot:1,machin:9,mai:[0,1],mainli:1,mani:1,manual:9,map:14,mathemat:0,matrix:14,mean:10,method:4,model:4,more:[0,9],most:1,musk:1,nearli:9,nerv:1,network:[10,19],neural:[10,19],noob:9,normal:6,nowadai:1,object:3,obviou:1,often:14,onli:[1,3],output:14,outsid:1,over:1,part:0,pass:11,path:1,peopl:9,power:1,predict:3,prestigi:1,pretti:4,prevent:1,pytorch:4,qualiti:3,quit:1,rage:1,rang:1,reason:1,recent:4,refer:[6,9,10,16,19],result:1,rnn:19,robot:1,same:4,search:1,secondli:1,section:0,seem:4,seen:1,set:3,shape:14,simpli:0,sinc:1,skip:0,small:6,snapchat:1,some:11,sometim:[1,14],subset:1,surviv:1,system:1,take:[1,6],target:14,tensorflow:4,term:1,thei:1,theori:1,thi:[0,4,14],thing:1,thirdli:1,those:1,time:14,todo:9,toolkit:14,top:1,transform:14,trick:1,tutori:9,two:14,used:[3,10],useful:1,vae:6,valu:11,vector:14,wai:1,want:[0,14],weight:14,where:1,which:1,who:9,work:10,world:1,would:1,yes:3,yield:1,you:[0,1,14],your:1},titles:["Approximation models","Getting Started","Gradients","Do loss functions have to be differentiable?","How are gradients calculated in deep learning systems?","AutoEncoder Model","Variational AutoEncoder Model","Generative Adversarial Models","Generative Models","Introduction","Convolution Layer","Dropout Layer","Embedding Layer","Layers","Linear Layer","Calculate gradients for Linear Layers","Normalization Layer","Padding Layer","Pooling Layer","Recurrent Layer","Self Attention Layer","Transformer Block","Transformer vs RNN","Classification","Gaussian Mixture Model","Expectation-Maximization Algorithm","Regression","Types of tasks"],titleterms:{"function":[2,3],adversari:7,algorithm:25,approxim:0,attent:20,auto:5,autoencod:[5,6],block:21,book:[1,9],calcul:[4,15],can:[0,2],classif:23,convolut:10,deep:4,differenti:3,doe:14,dropout:11,embed:12,encod:5,expect:25,find:2,gaussian:24,gener:[7,8],get:1,gradient:[2,4,15],have:3,how:[0,1,4,9,14,16,18],introduct:9,layer:[10,11,12,13,14,15,16,17,18,19,20],learn:[1,4],linear:[14,15],loss:3,machin:1,maxim:25,mean:6,mixtur:24,model:[0,5,6,7,8,24],norm:16,normal:16,pad:17,pool:18,prefac:1,recurr:19,regress:26,rnn:22,self:20,start:1,system:4,task:27,thi:[1,9],transform:[21,22],type:27,use:[1,5,9,10,14,16,17,18],useful:2,variat:6,well:0,what:[0,5,6,9,11,12,14,16,17,18,21],when:[2,5,10,14,16,17,18],why:[1,2,9,11],work:[11,14,16,18],you:6}})